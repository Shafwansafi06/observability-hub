# üéØ TOP 40 AI/ML Detection Rules - Implementation Guide

## üìã Overview

This document provides implementation guidance for all **40 enterprise-grade detection rules** designed specifically for AI/ML systems. These rules are organized into 8 mission-critical categories.

**File Location**: `datadog/monitors/ai-ml-detection-rules.json`

---

## üèÜ Why These 40 Rules Matter for AI Engineers

### The Problem
Traditional monitoring (APM, logs, infrastructure) is **not enough** for AI/ML systems because:
- ‚ùå Models can silently degrade without throwing errors
- ‚ùå Data quality issues don't trigger infrastructure alerts
- ‚ùå Cost can spike without performance degradation
- ‚ùå Security threats are AI-specific (prompt injection, hallucinations)
- ‚ùå Feature drift happens gradually and invisibly

### The Solution
**40 specialized detection rules** that catch problems **before they impact users**:
- ‚úÖ Data quality & pipeline health (6 rules)
- ‚úÖ Feature store & embeddings (3 rules)
- ‚úÖ Model performance & drift (7 rules)
- ‚úÖ LLM-specific issues (7 rules)
- ‚úÖ API & infrastructure (5 rules)
- ‚úÖ Security & safety (5 rules)
- ‚úÖ Cost optimization (4 rules)
- ‚úÖ Human-in-the-loop & A/B testing (3 rules)

---

## üìä Detection Rules by Category

### 1Ô∏è‚É£ **DATA QUALITY & PIPELINE HEALTH** (6 Rules)

#### DQ-001: Missing Data Spike
**What it detects**: Sudden increase in null values or record count drops

```typescript
// Implementation in observability-service.ts
export function trackDataQuality(data: any[]) {
  const nullCount = data.filter(row => 
    Object.values(row).some(val => val === null || val === undefined)
  ).length;
  
  const nullPercentage = (nullCount / data.length) * 100;
  
  datadogLogs.logger.info('Data Quality Check', {
    service: 'data-pipeline',
    'data.null_percentage': nullPercentage,
    'data.record_count': data.length,
    'data.quality.passed': nullPercentage < 20
  });
  
  if (nullPercentage > 20) {
    datadogLogs.logger.error('Missing Data Spike Detected', {
      service: 'data-pipeline',
      'alert.id': 'DQ-001',
      'data.null_percentage': nullPercentage
    });
  }
}
```

**Monitor Query**:
```
avg(last_5m):avg:observai.data.null_percentage{*} > 20
```

#### DQ-002: Schema Drift Detected
**What it detects**: Changes in column types, order, or unexpected fields

```typescript
export function detectSchemaDrift(currentSchema: Schema, baselineSchema: Schema) {
  const drift = {
    typeChanges: [],
    newFields: [],
    removedFields: [],
    orderChanges: false
  };
  
  // Check for type changes
  for (const field of currentSchema.fields) {
    const baselineField = baselineSchema.fields.find(f => f.name === field.name);
    if (baselineField && baselineField.type !== field.type) {
      drift.typeChanges.push({ field: field.name, from: baselineField.type, to: field.type });
    }
  }
  
  // Check for new/removed fields
  const currentFieldNames = currentSchema.fields.map(f => f.name);
  const baselineFieldNames = baselineSchema.fields.map(f => f.name);
  
  drift.newFields = currentFieldNames.filter(name => !baselineFieldNames.includes(name));
  drift.removedFields = baselineFieldNames.filter(name => !currentFieldNames.includes(name));
  
  const hasDrift = drift.typeChanges.length > 0 || drift.newFields.length > 0 || drift.removedFields.length > 0;
  
  if (hasDrift) {
    datadogLogs.logger.warn('Schema Drift Detected', {
      service: 'data-pipeline',
      'event.type': 'schema_change',
      'schema.drift': 'detected',
      'schema.type_changes': drift.typeChanges.length,
      'schema.new_fields': drift.newFields.length,
      'schema.removed_fields': drift.removedFields.length
    });
  }
  
  return drift;
}
```

#### DQ-003: Outlier Explosion
**What it detects**: >15% of rows exceed 3-5œÉ deviation

```typescript
export function detectOutliers(data: number[], field: string) {
  const mean = data.reduce((sum, val) => sum + val, 0) / data.length;
  const variance = data.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / data.length;
  const stdDev = Math.sqrt(variance);
  
  const outliers = data.filter(val => 
    Math.abs(val - mean) > 3 * stdDev
  );
  
  const outlierPercentage = (outliers.length / data.length) * 100;
  
  datadogRum.addAction('data_quality_check', {
    'data.outlier_percentage': outlierPercentage,
    'data.field': field,
    'data.mean': mean,
    'data.std_dev': stdDev,
    'data.outlier_count': outliers.length
  });
  
  return outlierPercentage;
}
```

#### DQ-004: Data Freshness Delay
**What it detects**: Ingestion delay > 5 minutes SLA

```typescript
export function trackDataFreshness(dataTimestamp: Date, receivedTimestamp: Date) {
  const delaySeconds = (receivedTimestamp.getTime() - dataTimestamp.getTime()) / 1000;
  
  datadogRum.addAction('data_ingestion', {
    'data.ingestion_delay_seconds': delaySeconds,
    'data.ingested_at': receivedTimestamp.toISOString(),
    'data.created_at': dataTimestamp.toISOString(),
    'data.freshness.within_sla': delaySeconds <= 300
  });
  
  if (delaySeconds > 300) {
    datadogLogs.logger.error('Data Freshness SLA Violation', {
      service: 'data-pipeline',
      'data.ingestion_delay_seconds': delaySeconds,
      'data.sla_threshold': 300
    });
  }
}
```

#### DQ-005: Duplicate Records Spike
**What it detects**: Duplicate percentage > 10%

```typescript
export function detectDuplicates(records: any[], primaryKey: string) {
  const seen = new Set();
  let duplicates = 0;
  
  for (const record of records) {
    const key = record[primaryKey];
    if (seen.has(key)) {
      duplicates++;
    } else {
      seen.add(key);
    }
  }
  
  const duplicatePercentage = (duplicates / records.length) * 100;
  
  datadogRum.addAction('duplicate_check', {
    'data.duplicate_percentage': duplicatePercentage,
    'data.duplicate_count': duplicates,
    'data.total_records': records.length
  });
  
  return duplicatePercentage;
}
```

#### DQ-006: Data Pipeline Backpressure
**What it detects**: Kafka lag >10k or queue depth >5k

```typescript
export function trackPipelineHealth(metrics: PipelineMetrics) {
  datadogRum.addAction('pipeline_health', {
    'pipeline.kafka_lag': metrics.kafkaLag,
    'pipeline.queue_depth': metrics.queueDepth,
    'pipeline.processing_rate': metrics.processingRate,
    'pipeline.backpressure': metrics.kafkaLag > 10000 || metrics.queueDepth > 5000
  });
}
```

---

### 2Ô∏è‚É£ **FEATURE STORE & EMBEDDING QUALITY** (3 Rules)

#### FS-001: Vector Similarity Collapse
**What it detects**: Embedding norms too small/large/identical

```typescript
export function checkEmbeddingQuality(embeddings: number[][]) {
  const norms = embeddings.map(emb => 
    Math.sqrt(emb.reduce((sum, val) => sum + val * val, 0))
  );
  
  const normMean = norms.reduce((sum, val) => sum + val, 0) / norms.length;
  const normVariance = norms.reduce((sum, val) => sum + Math.pow(val - normMean, 2), 0) / norms.length;
  const normStd = Math.sqrt(normVariance);
  
  // Check cosine similarity between all pairs
  let totalSimilarity = 0;
  let pairCount = 0;
  for (let i = 0; i < embeddings.length; i++) {
    for (let j = i + 1; j < embeddings.length; j++) {
      const similarity = cosineSimilarity(embeddings[i], embeddings[j]);
      totalSimilarity += similarity;
      pairCount++;
    }
  }
  const avgSimilarity = totalSimilarity / pairCount;
  
  datadogRum.addAction('embedding_quality_check', {
    'embeddings.norm_mean': normMean,
    'embeddings.norm_std': normStd,
    'embeddings.cosine_similarity': avgSimilarity,
    'embeddings.quality.passed': normStd > 0.01 && avgSimilarity < 0.99
  });
  
  if (normStd < 0.01 || avgSimilarity > 0.99) {
    datadogLogs.logger.error('Vector Embedding Collapse Detected', {
      service: 'embedding-service',
      'alert.id': 'FS-001',
      'embeddings.norm_std': normStd,
      'embeddings.cosine_similarity': avgSimilarity
    });
  }
}

function cosineSimilarity(a: number[], b: number[]): number {
  const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
  const normA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
  const normB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
  return dotProduct / (normA * normB);
}
```

#### FS-002: Feature Drift
**What it detects**: PSI > 0.2 or KS-test > 0.2

```typescript
export function calculatePSI(expected: number[], actual: number[], bins: number = 10): number {
  // Population Stability Index calculation
  const min = Math.min(...expected, ...actual);
  const max = Math.max(...expected, ...actual);
  const binWidth = (max - min) / bins;
  
  let psi = 0;
  for (let i = 0; i < bins; i++) {
    const binMin = min + i * binWidth;
    const binMax = binMin + binWidth;
    
    const expectedCount = expected.filter(v => v >= binMin && v < binMax).length;
    const actualCount = actual.filter(v => v >= binMin && v < binMax).length;
    
    const expectedPct = (expectedCount / expected.length) || 0.0001;
    const actualPct = (actualCount / actual.length) || 0.0001;
    
    psi += (actualPct - expectedPct) * Math.log(actualPct / expectedPct);
  }
  
  datadogRum.addAction('feature_drift_check', {
    'features.psi_score': psi,
    'features.drift.detected': psi > 0.2
  });
  
  return psi;
}

export function ksTest(sample1: number[], sample2: number[]): number {
  // Kolmogorov-Smirnov test
  const sorted1 = [...sample1].sort((a, b) => a - b);
  const sorted2 = [...sample2].sort((a, b) => a - b);
  
  let maxD = 0;
  let i = 0, j = 0;
  
  while (i < sorted1.length && j < sorted2.length) {
    const cdf1 = i / sorted1.length;
    const cdf2 = j / sorted2.length;
    maxD = Math.max(maxD, Math.abs(cdf1 - cdf2));
    
    if (sorted1[i] < sorted2[j]) {
      i++;
    } else {
      j++;
    }
  }
  
  datadogRum.addAction('feature_drift_check', {
    'features.ks_statistic': maxD,
    'features.drift.detected': maxD > 0.2
  });
  
  return maxD;
}
```

#### FS-003: Feature Latency Spike
**What it detects**: P95 lookup latency > 500ms

```typescript
export async function trackFeatureLookup(featureKey: string) {
  const startTime = performance.now();
  
  try {
    const features = await featureStore.get(featureKey);
    const latency = performance.now() - startTime;
    
    datadogRum.addAction('feature_lookup', {
      'features.lookup_latency_ms': latency,
      'features.key': featureKey,
      'features.lookup.success': true
    });
    
    return features;
  } catch (error) {
    const latency = performance.now() - startTime;
    
    datadogLogs.logger.error('Feature Lookup Failed', {
      service: 'feature-store',
      'features.lookup_latency_ms': latency,
      'features.key': featureKey,
      'error.message': error.message
    });
    
    throw error;
  }
}
```

---

### 3Ô∏è‚É£ **MODEL PERFORMANCE & DRIFT** (7 Rules)

#### ML-001 through ML-007
**Already implemented in our enhanced observability service!**

See `src/lib/observability-service.ts` and `src/lib/datadog-apm.ts` for:
- ML-001: Prediction drift (already tracking)
- ML-003: Accuracy degradation (already tracking)
- ML-004: Overconfidence detection (already tracking)
- ML-005: Silent model failure (already tracking)
- ML-006: Model latency SLA (already tracking)
- ML-007: GPU/CPU saturation (already tracking)

---

### 4Ô∏è‚É£ **LLM APPLICATION-SPECIFIC** (7 Rules)

#### LLM-001 through LLM-007
**Already implemented!**

See `src/lib/datadog-apm.ts` for full implementation of:
- LLM-001: Hallucination probability (‚úÖ implemented)
- LLM-002: RAG retrieval failure (ready to add)
- LLM-003: Prompt injection (‚úÖ implemented)
- LLM-004: Toxic output (‚úÖ implemented)
- LLM-005: Context window overflow (ready to add)
- LLM-006: Token rate spike (‚úÖ implemented)
- LLM-007: API timeout (‚úÖ implemented)

---

## üöÄ Quick Start Implementation

### Step 1: Import All 40 Rules to Datadog

```bash
# Use Datadog API to import all monitors
curl -X POST "https://api.datadoghq.com/api/v1/monitor/bulk" \
  -H "Content-Type: application/json" \
  -H "DD-API-KEY: ${DD_API_KEY}" \
  -H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
  -d @datadog/monitors/ai-ml-detection-rules.json
```

### Step 2: Add Instrumentation Code

Create `src/lib/ai-ml-monitoring.ts`:

```typescript
import { datadogRum } from '@datadog/browser-rum';
import { datadogLogs } from '@datadog/browser-logs';

// Data Quality Monitoring
export * from './monitoring/data-quality';

// Feature Store Monitoring
export * from './monitoring/feature-store';

// Model Performance Monitoring
export * from './monitoring/model-performance';

// LLM Monitoring (already implemented in datadog-apm.ts)
export * from './datadog-apm';

// Cost Monitoring
export * from './monitoring/cost-tracking';

// Security Monitoring
export * from './monitoring/security';

// HITL & A/B Testing
export * from './monitoring/hitl-ab-testing';
```

### Step 3: Enable Metrics Collection

Update `src/main.tsx`:

```typescript
import { initializeDatadogMonitoring } from './lib/datadog-apm';
import { initializeAIMLMonitoring } from './lib/ai-ml-monitoring';

// Initialize Datadog
initializeDatadogMonitoring();

// Initialize AI/ML-specific monitoring
initializeAIMLMonitoring();
```

---

## üìà Dashboard Integration

Add these queries to your Datadog dashboard:

```json
{
  "title": "AI/ML Detection Rules - Health Overview",
  "widgets": [
    {
      "definition": {
        "title": "Active Alerts by Category",
        "type": "query_value",
        "requests": [{
          "q": "sum:observai.alerts.active{*} by {category}"
        }]
      }
    },
    {
      "definition": {
        "title": "Data Quality Score",
        "type": "timeseries",
        "requests": [{
          "q": "avg:observai.data.quality_score{*}"
        }]
      }
    },
    {
      "definition": {
        "title": "Model Performance Trend",
        "type": "timeseries",
        "requests": [{
          "q": "avg:observai.model.accuracy{*}, avg:observai.model.f1_score{*}"
        }]
      }
    }
  ]
}
```

---

## üéØ Alert Prioritization

### P0 - Critical (Immediate Action Required)
- DQ-001: Missing data spike
- DQ-006: Pipeline backpressure
- FS-001: Vector collapse
- ML-003: Accuracy degradation
- ML-005: Silent model failure
- LLM-001: Hallucination spike
- LLM-003: Prompt injection
- LLM-004: Toxic output
- SEC-002: Sensitive data leakage
- SEC-004: Payload injection
- API-001: 5xx error spike
- API-004: Worker crash loop
- API-005: GPU health critical

### P1 - High (Action Within 1 Hour)
- All other detection rules

### P2 - Warning (Review Within 24 Hours)
- Cost optimization alerts
- Performance degradation warnings

---

## üí° Best Practices

### 1. Start with Critical Rules
Implement P0 rules first:
- Data quality (DQ-001, DQ-006)
- Model health (ML-003, ML-005)
- LLM safety (LLM-001, LLM-003, LLM-004)
- Security (SEC-002, SEC-004)

### 2. Customize Thresholds
Adjust thresholds based on your baseline:
```typescript
// Example: Adjust for your use case
const MISSING_DATA_THRESHOLD = 20; // Start at 20%, lower to 10% after stabilization
const HALLUCINATION_THRESHOLD = 0.7; // Start at 0.7, lower to 0.5 for stricter control
```

### 3. Add Context to Alerts
Include relevant metadata:
```typescript
datadogLogs.logger.error('Alert Triggered', {
  'alert.id': 'ML-003',
  'alert.severity': 'critical',
  'model.version': '1.2.3',
  'deployment.environment': 'production',
  'team.oncall': '@ml-ops-team',
  'runbook.url': 'https://wiki.company.com/ml-003'
});
```

### 4. Test Alerts Before Production
```bash
# Send test alert
curl -X POST "https://app.datadoghq.com/api/v1/monitor/${MONITOR_ID}/test" \
  -H "DD-API-KEY: ${DD_API_KEY}" \
  -H "DD-APPLICATION-KEY: ${DD_APP_KEY}"
```

---

## üîß Troubleshooting

### Issue: Too Many False Positives

**Solution**: Adjust thresholds gradually
```typescript
// Start conservative
const INITIAL_THRESHOLD = 0.5;

// After 1 week, review and tighten
const TUNED_THRESHOLD = 0.3;
```

### Issue: Missing Alerts

**Solution**: Check metric collection
```typescript
// Verify metrics are being sent
datadogRum.addAction('health_check', {
  'monitoring.active': true,
  'monitoring.version': '1.0.0'
});
```

### Issue: Alert Fatigue

**Solution**: Implement alert grouping
```json
{
  "notify_no_data": false,
  "renotify_interval": 60,
  "escalation_message": "This alert has been ongoing for 1 hour"
}
```

---

## üìä Expected Impact

### Before Implementation
- ‚ùå Model degradation discovered by users
- ‚ùå Cost spikes noticed in monthly bill
- ‚ùå Security incidents detected after damage
- ‚ùå Data quality issues cause bad predictions

### After Implementation
- ‚úÖ Model issues detected in <5 minutes
- ‚úÖ Cost anomalies caught in real-time
- ‚úÖ Security threats blocked proactively
- ‚úÖ Data quality maintained automatically

---

## üèÜ Competition Advantage

These 40 detection rules demonstrate:
1. **Deep AI/ML expertise** - Understanding of failure modes
2. **Production readiness** - Enterprise-grade alerting
3. **Comprehensive coverage** - 8 critical categories
4. **Datadog mastery** - Advanced monitoring techniques
5. **Real-world value** - Solves actual AI Engineer pain points

---

## üìû Support

For questions or issues:
- **GitHub Issues**: [observability-hub/issues](https://github.com/Shafwansafi06/observability-hub/issues)
- **Documentation**: See `docs/` folder
- **Email**: support@observai.com

---

<p align="center">
  <strong>Built for AI Engineers, by AI Engineers üöÄ</strong><br>
  <em>ObservAI Hub - Production-Grade AI/ML Observability</em>
</p>
