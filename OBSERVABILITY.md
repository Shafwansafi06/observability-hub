# ğŸ§  ObservAI Hub - LLM Observability Platform

[![Datadog](https://img.shields.io/badge/Datadog-632CA6?style=for-the-badge&logo=datadog&logoColor=white)](https://www.datadoghq.com/)
[![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)](https://cloud.google.com/)
[![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)](https://supabase.com/)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)

> **End-to-end LLM observability with deep telemetry, anomaly detection, and automated incident management. Built for the next generation of AI engineers.**

---

## ğŸ¯ Project Overview

ObservAI is a comprehensive observability platform specifically designed for LLM-powered applications. It combines infrastructure, application, and AI-level telemetry to provide unprecedented visibility into your AI systems.

### Key Features

- ğŸ” **LLM-Level Telemetry**: Track tokens, latencies, confidence scores, embeddings, and prompt-response pairs
- ğŸ›¡ï¸ **AI Safety Detection**: Detect hallucinations, prompt injections, data leakage, and other AI-specific failures
- âš¡ **Sub-second Alerting**: Get notified within seconds of anomalies with context-rich incident packages
- ğŸ“Š **Advanced Analytics**: Datadog dashboards with infrastructure, app, and model metrics in one view
- ğŸ¤– **Automated Incidents**: Auto-create Datadog incidents with traces, runbooks, and debugging context
- ğŸ” **Security & Compliance**: PII detection, audit logs, and GDPR-compliant data handling

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (React + Vite)                     â”‚
â”‚                   Datadog RUM + Session Replay                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Gateway (Supabase Edge Functions)          â”‚
â”‚                  OpenTelemetry + Datadog APM                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Supabase    â”‚ â”‚  Vertex AI   â”‚ â”‚  Datadog     â”‚
    â”‚  PostgreSQL  â”‚ â”‚  (Gemini)    â”‚ â”‚  Platform    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- Supabase account (already configured)
- Datadog account ([Sign up free](https://www.datadoghq.com/))
- Google Cloud account with Vertex AI enabled (optional)

### 1. Clone & Install

\`\`\`bash
git clone https://github.com/your-org/observability-hub.git
cd observability-hub
npm install
\`\`\`

### 2. Configure Environment

Copy \`.env.example\` to \`.env\` and fill in your credentials:

\`\`\`bash
# Already configured âœ…
VITE_SUPABASE_URL=https://nztdwsnmttwwjticuphi.supabase.co
VITE_SUPABASE_ANON_KEY=your_anon_key

# Add these âš ï¸
VITE_DD_APPLICATION_ID=your_datadog_app_id
VITE_DD_CLIENT_TOKEN=your_datadog_client_token
DD_API_KEY=your_datadog_api_key

# Optional: Vertex AI
VITE_GCP_PROJECT_ID=your_gcp_project
GCP_SERVICE_ACCOUNT_KEY=your_service_account_json
\`\`\`

### 3. Test Database Connection

\`\`\`bash
npm run test:db
\`\`\`

Expected output:
\`\`\`
âœ… PASS       | Database Connection                 | Connected successfully
âœ… EXISTS     | Table: organizations
âœ… EXISTS     | Table: llm_metrics
... (all 13 tables)
âœ… All critical tests passed! Supabase is ready.
\`\`\`

### 4. Run Development Server

\`\`\`bash
npm run dev
\`\`\`

Visit: [http://localhost:5173](http://localhost:5173)

### 5. Build for Production

\`\`\`bash
npm run build
npm run preview
\`\`\`

---

## ğŸ“Š Datadog Setup

### Step 1: Get Datadog Credentials

1. Log in to [Datadog](https://app.datadoghq.com/)
2. Go to **Organization Settings** â†’ **API Keys**
3. Create a new API key for backend
4. Go to **Organization Settings** â†’ **Client Tokens**
5. Create a new client token for frontend RUM
6. Go to **UX Monitoring** â†’ **RUM Applications**
7. Create a new application and note the Application ID

### Step 2: Import Dashboards

\`\`\`bash
cd datadog/dashboards
# Use Datadog API or Terraform to import dashboards
terraform apply
\`\`\`

Or manually import via Datadog UI:
- Dashboard â†’ New Dashboard â†’ Import JSON
- Upload \`datadog/dashboards/llm-overview.json\`

### Step 3: Configure Monitors

\`\`\`bash
# Import monitors using Datadog Terraform provider
cd datadog
terraform init
terraform plan
terraform apply
\`\`\`

### Step 4: Set Up Log Pipelines

1. Go to **Logs** â†’ **Pipelines** in Datadog
2. Create new pipeline: "LLM Inference Processing"
3. Copy configuration from \`datadog/log-pipelines.yaml\`
4. Add processors as defined in the YAML

---

## ğŸ” Observability Features

### Real User Monitoring (RUM)

- âœ… Page load performance tracking
- âœ… User interaction tracking
- âœ… Session replay (20% of sessions)
- âœ… Error tracking with full stack traces
- âœ… Custom LLM event tracking

### Application Performance Monitoring (APM)

- âœ… Distributed tracing across all services
- âœ… Trace correlation with logs
- âœ… Database query performance
- âœ… External API call tracking
- âœ… Custom spans for LLM operations

### Log Management

- âœ… Structured JSON logging
- âœ… Automatic log parsing and enrichment
- âœ… PII redaction
- âœ… Log-to-trace correlation
- âœ… Custom facets for LLM metrics

### Custom Metrics

Key LLM metrics tracked:
- \`ai.requests.count\` - Total AI requests
- \`ai.model.latency\` - Model inference latency (p50/p95/p99)
- \`ai.prompt.tokens\` - Prompt token count
- \`ai.response.tokens\` - Response token count
- \`ai.confidence\` - Model confidence score
- \`ai.hallucination.score\` - Hallucination risk score
- \`ai.embedding.distance\` - Embedding drift metric
- \`billing.api_cost.usd\` - API cost tracking

### Anomaly Detection

9 pre-configured monitors for:
1. **Hallucination Detection** - High hallucination risk
2. **High Latency** - Model inference > 2s
3. **Cost Spikes** - Unusual token usage
4. **Prompt Injection** - Security threats
5. **PII Leakage** - Data privacy violations
6. **Model Drift** - Embedding distance increase
7. **Error Rate** - High failure rate
8. **Streaming Issues** - WebSocket disruptions
9. **System Health** - Composite health check

---

## ğŸ› ï¸ Development

### Project Structure

\`\`\`
observability-hub/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ datadog.ts              # Datadog instrumentation
â”‚   â”‚   â”œâ”€â”€ supabaseClient.ts       # Supabase client config
â”‚   â”‚   â”œâ”€â”€ api-hooks.ts            # TanStack Query hooks
â”‚   â”‚   â””â”€â”€ realtime.ts             # Real-time subscriptions
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ dashboard/
â”‚   â”‚       â”œâ”€â”€ Overview.tsx        # Main dashboard
â”‚   â”‚       â”œâ”€â”€ LLMMetrics.tsx      # LLM-specific metrics
â”‚   â”‚       â”œâ”€â”€ Anomalies.tsx       # Anomaly detection
â”‚   â”‚       â””â”€â”€ LogStream.tsx       # Live log viewer
â”‚   â””â”€â”€ components/                 # Reusable UI components
â”œâ”€â”€ supabase/
â”‚   â”œâ”€â”€ functions/                  # Edge Functions (Deno)
â”‚   â”‚   â”œâ”€â”€ ingest/                 # Telemetry ingestion
â”‚   â”‚   â””â”€â”€ cron/                   # Background jobs
â”‚   â””â”€â”€ migrations/                 # Database schema
â”œâ”€â”€ datadog/
â”‚   â”œâ”€â”€ datadog.yaml                # Agent configuration
â”‚   â”œâ”€â”€ log-pipelines.yaml          # Log processing rules
â”‚   â”œâ”€â”€ monitors.yaml               # Alert definitions
â”‚   â””â”€â”€ dashboards/                 # Dashboard JSONs
â”œâ”€â”€ config/
â”‚   â””â”€â”€ observability/
â”‚       â””â”€â”€ otel-collector-config.yaml  # OpenTelemetry config
â””â”€â”€ scripts/
    â””â”€â”€ test-supabase-connection.ts # Database connectivity test
\`\`\`

### Available Scripts

\`\`\`bash
npm run dev          # Start development server
npm run build        # Build for production
npm run preview      # Preview production build
npm run lint         # Run ESLint
npm run test:db      # Test Supabase connection
\`\`\`

### Adding Custom Metrics

\`\`\`typescript
import { trackLLMEvent } from '@/lib/datadog';

// Track LLM request
trackLLMEvent({
  model: 'gemini-pro',
  promptTokens: 128,
  responseTokens: 256,
  latency: 1234,
  confidence: 0.91
});
\`\`\`

### Tracking Hallucinations

\`\`\`typescript
import { trackHallucinationEvent } from '@/lib/datadog';

trackHallucinationEvent({
  model: 'gemini-pro',
  score: 0.75,
  requestId: 'req-123',
  embeddingDistance: 0.42
});
\`\`\`

---

## ğŸ“ˆ Monitoring Best Practices

### 1. Set Up Alerts

Configure notification channels:
- Slack: \`#observai-oncall\`
- PagerDuty: Critical incidents
- Email: Non-critical alerts

### 2. Review Dashboards Daily

Key metrics to watch:
- Request volume trends
- Latency percentiles (p95, p99)
- Error rate < 1%
- Hallucination detections
- Cost per 1M tokens

### 3. Incident Response

When an alert fires:
1. Check Datadog dashboard
2. Review attached traces
3. Analyze log context
4. Follow runbook steps
5. Document resolution

### 4. Cost Optimization

Monitor these metrics:
- Token usage by model
- Cost per organization
- Unused API keys
- Inefficient prompts

---

## ğŸ” Security & Compliance

### PII Protection

- âœ… Automatic PII detection in logs
- âœ… Redaction of sensitive data
- âœ… GDPR-compliant data handling
- âœ… Audit logs for all data access

### API Key Security

- âœ… Keys stored in environment variables
- âœ… Never committed to version control
- âœ… Automatic key rotation support
- âœ… Rate limiting per API key

### Data Retention

- Logs: 15 days (configurable)
- Metrics: 15 months
- Traces: 15 days
- RUM sessions: 30 days

---

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“š Documentation

- [Architecture Guide](docs/ARCHITECTURE.md)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Security Best Practices](docs/SECURITY.md)
- [API Documentation](docs/API.md)

---

## ğŸ“ Learning Resources

### Datadog
- [Datadog RUM Documentation](https://docs.datadoghq.com/real_user_monitoring/)
- [OpenTelemetry with Datadog](https://docs.datadoghq.com/tracing/setup_overview/open_standards/otel_collector_datadog_exporter/)
- [Log Management Guide](https://docs.datadoghq.com/logs/)

### Vertex AI
- [Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs)
- [Gemini API Reference](https://ai.google.dev/docs)

### Supabase
- [Supabase Edge Functions](https://supabase.com/docs/guides/functions)
- [PostgreSQL Performance](https://supabase.com/docs/guides/database/performance)

---

## ğŸ“Š Demo & Screenshots

### Dashboard Preview

![LLM Overview Dashboard](docs/images/dashboard-overview.png)

### Hallucination Detection

![Hallucination Alert](docs/images/hallucination-alert.png)

### Cost Tracking

![Cost Analysis](docs/images/cost-tracking.png)

---

## âœ… Deployment Checklist

- [ ] Configure \`.env\` with all credentials
- [ ] Test database connection (\`npm run test:db\`)
- [ ] Import Datadog dashboards
- [ ] Configure Datadog monitors
- [ ] Set up log pipelines
- [ ] Configure alert notification channels
- [ ] Deploy Edge Functions to Supabase
- [ ] Enable Vertex AI API in GCP
- [ ] Set up Upstash Redis (optional)
- [ ] Configure custom domain (optional)
- [ ] Enable HTTPS/SSL
- [ ] Set up CI/CD pipeline
- [ ] Load test with synthetic traffic
- [ ] Document runbooks
- [ ] Train team on incident response

---

## ğŸ† Hackathon Submission

**Event**: Datadog Ã— Google Cloud Hackathon 2024

**Category**: Observability for AI Applications

**Demo Video**: [Watch on YouTube](https://youtube.com/watch?v=...)

**Live Demo**: [https://observai.dev](https://observai.dev)

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details

---

## ğŸ™ Acknowledgments

- **Datadog** - For the amazing observability platform
- **Google Cloud** - For Vertex AI and infrastructure
- **Supabase** - For the backend platform
- **Open Source Community** - For all the great tools

---

## ğŸ“§ Contact

- **Email**: team@observai.dev
- **Twitter**: [@ObservAI](https://twitter.com/observai)
- **Discord**: [Join our community](https://discord.gg/observai)
- **GitHub**: [observai/observability-hub](https://github.com/observai/observability-hub)

---

<div align="center">

**Built with â¤ï¸ for the AI engineering community**

[â­ Star us on GitHub](https://github.com/observai/observability-hub) | [ğŸ¦ Follow on Twitter](https://twitter.com/observai) | [ğŸ“– Read the docs](https://docs.observai.dev)

</div>
