# ===============================================================================
# ObservAI Hub - Datadog Agent Configuration
# Complete observability pipeline for LLM applications
# ===============================================================================

# Agent Identification
api_key: ${DD_API_KEY}
site: datadoghq.com
hostname: observai-hub
tags:
  - env:production
  - service:observai
  - version:1.0.0
  - team:platform
  - project:observai-hub

# ===============================================================================
# LOGS CONFIGURATION
# ===============================================================================
logs_enabled: true
logs_config:
  container_collect_all: true
  processing_rules:
    # Redact PII from logs
    - type: mask_sequences
      name: redact_api_keys
      replace_placeholder: "[REDACTED_API_KEY]"
      pattern: "(sk|pk|apikey)_[a-zA-Z0-9]{32,}"
    
    - type: mask_sequences
      name: redact_emails
      replace_placeholder: "[REDACTED_EMAIL]"
      pattern: "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}"
    
    - type: mask_sequences
      name: redact_jwt
      replace_placeholder: "[REDACTED_TOKEN]"
      pattern: "eyJ[a-zA-Z0-9_-]+\\.eyJ[a-zA-Z0-9_-]+\\.[a-zA-Z0-9_-]+"
  
  # LLM-specific log sources
  logs:
    - type: file
      path: /var/log/observai/llm-inference.log
      service: vertex-ai
      source: llm
      tags:
        - type:model_inference
        - criticality:high
    
    - type: file
      path: /var/log/observai/api-gateway.log
      service: api-gateway
      source: nodejs
      tags:
        - type:api
        - layer:gateway
    
    - type: file
      path: /var/log/observai/edge-functions.log
      service: edge-functions
      source: deno
      tags:
        - type:serverless
        - runtime:deno

# ===============================================================================
# APM (Application Performance Monitoring)
# ===============================================================================
apm_config:
  enabled: true
  receiver_port: 8126
  receiver_socket: /var/run/datadog/apm.socket
  
  # Sampling Configuration
  max_traces_per_second: 200
  errors_per_second: 10
  
  # LLM-specific trace filtering
  filter_tags:
    require:
      - "resource_type:llm_inference"
    reject:
      - "http.status_code:404"
  
  # Resource name patterns
  replace_tags:
    - name: "resource.name"
      pattern: "/api/v1/models/.*/infer"
      repl: "/api/v1/models/{model_id}/infer"
    
    - name: "resource.name"
      pattern: "/api/v1/prompts/.*/execute"
      repl: "/api/v1/prompts/{prompt_id}/execute"
  
  # Custom trace analytics
  analyzed_spans:
    llm_inference: 1.0
    api_request: 1.0
    database_query: 0.5
    cache_operation: 0.1

# ===============================================================================
# METRICS CONFIGURATION
# ===============================================================================
use_dogstatsd: true
dogstatsd_port: 8125
dogstatsd_socket: /var/run/datadog/dsd.socket
dogstatsd_non_local_traffic: true

# Custom Metrics Configuration
histogram_aggregates:
  - "max"
  - "median"
  - "avg"
  - "count"
  - "p95"
  - "p99"

histogram_percentiles:
  - 0.5
  - 0.75
  - 0.95
  - 0.99

# Distribution Metrics for LLM
distribution_metrics:
  - ai.model.latency
  - ai.token.count
  - ai.prompt.length
  - ai.response.length
  - ai.embedding.similarity
  - ai.hallucination.score

# ===============================================================================
# PROCESS MONITORING
# ===============================================================================
process_config:
  enabled: true
  intervals:
    container: 10
    process: 30
  
  # Track LLM-related processes
  process_discovery:
    enabled: true
    hints:
      - name: "vertex-ai-proxy"
      - name: "model-server"
      - name: "embedding-service"

# ===============================================================================
# LIVE PROCESSES & CONTAINERS
# ===============================================================================
process_config:
  enabled: "true"
  container_collection:
    enabled: true

# ===============================================================================
# NETWORK PERFORMANCE MONITORING
# ===============================================================================
network_config:
  enabled: true

# ===============================================================================
# REAL USER MONITORING (RUM) & SESSION REPLAY
# ===============================================================================
# Frontend RUM is configured separately via JavaScript SDK

# ===============================================================================
# SERVICE CHECKS
# ===============================================================================
service_discovery:
  enabled: true

# Health checks for critical services
check_runners: 4

# Custom service checks
service_checks:
  - name: vertex_ai_availability
    check_command: "/opt/datadog-agent/bin/check_vertex_ai.sh"
    interval: 60
    timeout: 10
    tags:
      - service:vertex-ai
      - criticality:high
  
  - name: supabase_connection
    check_command: "/opt/datadog-agent/bin/check_supabase.sh"
    interval: 30
    timeout: 5
    tags:
      - service:supabase
      - criticality:high
  
  - name: redis_cache
    check_command: "/opt/datadog-agent/bin/check_redis.sh"
    interval: 30
    timeout: 5
    tags:
      - service:redis
      - criticality:medium

# ===============================================================================
# INTEGRATIONS
# ===============================================================================
confd_path: /etc/datadog-agent/conf.d

# PostgreSQL Integration (Supabase)
postgres:
  host: ${SUPABASE_DB_HOST}
  port: 5432
  username: ${SUPABASE_DB_USER}
  password: ${SUPABASE_DB_PASSWORD}
  dbname: postgres
  tags:
    - db:supabase
    - service:postgresql
  collect_database_size_metrics: true
  collect_default_database: true
  custom_queries:
    - metric_prefix: observai.db
      query: |
        SELECT 
          COUNT(*) as metric_count,
          'metrics' as table_name,
          extract(epoch from now() - created_at) as age_seconds
        FROM metrics
        WHERE created_at > now() - interval '1 hour'
      columns:
        - name: table_name
          type: tag
        - name: metric_count
          type: gauge
        - name: age_seconds
          type: gauge
    
    - metric_prefix: observai.llm
      query: |
        SELECT 
          model_name,
          COUNT(*) as request_count,
          AVG(total_tokens) as avg_tokens,
          AVG(latency_ms) as avg_latency,
          AVG(confidence_score) as avg_confidence
        FROM llm_metrics
        WHERE created_at > now() - interval '5 minutes'
        GROUP BY model_name
      columns:
        - name: model_name
          type: tag
        - name: request_count
          type: gauge
        - name: avg_tokens
          type: gauge
        - name: avg_latency
          type: gauge
        - name: avg_confidence
          type: gauge

# Redis Integration (Upstash)
redis:
  host: ${UPSTASH_REDIS_HOST}
  port: ${UPSTASH_REDIS_PORT}
  password: ${UPSTASH_REDIS_TOKEN}
  tags:
    - service:redis
    - provider:upstash
  warn_on_missing_keys: false

# ===============================================================================
# CLOUD INTEGRATIONS
# ===============================================================================
# Google Cloud Platform
# Configured via GCP Integration in Datadog UI
# Monitors: GKE, Cloud Run, Vertex AI, Cloud SQL

# ===============================================================================
# PERFORMANCE & RESOURCE LIMITS
# ===============================================================================
# Agent resource constraints
max_proc_fds: 8192
cmd_port: 5001
GUI_port: 5002

# Forwarder settings
forwarder_timeout: 20
forwarder_retry_queue_max_size: 30

# Internal profiling
go_expvar_port: 5000
expvar_port: 5000

# ===============================================================================
# ADVANCED FEATURES
# ===============================================================================
# Compliance & Security
compliance_config:
  enabled: true
  check_interval: 1h

# Synthetic Monitoring
# Configured via Datadog Synthetics UI

# Incident Management
# Configured via Datadog Incidents API

# ===============================================================================
# TROUBLESHOOTING
# ===============================================================================
log_level: info
log_file: /var/log/datadog/agent.log
log_format_json: true

# Enable debug mode if needed
# log_level: debug
# log_all_goroutines_when_unhealthy: true
